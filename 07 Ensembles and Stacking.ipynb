{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"http://sydney.edu.au/images/content/about/logo-mono.jpg\">\n",
    "<h1 align=\"center\" style=\"margin-top:10px\">Machine Learning Using Python (MEAFA Workshop)</h1>\n",
    "<h2 align=\"center\" style=\"margin-top:10px\">Lesson 7: Ensembles and Stacking</h2>\n",
    "<br>\n",
    "\n",
    "<a href=\"#Data:-Twitter-Airline-Sentiment\">Twitter Airline Sentiment Data</a> <br>\n",
    "<a href=\"#Data Preparation\">Data Preparation</a> <br>\n",
    "<a href=\"#Text-Classification-Algorithms\">Text Classification Models</a> <br>\n",
    "<a href=\"#Voting-Classifier\">Voting Classifier</a> <br>\n",
    "<a href=\"#Model-Stacking\">Model Stacking</a> <br>\n",
    "<a href=\"#Model-Evaluation\">Model Evaluation</a> <br>\n",
    "\n",
    "This notebook relies on the following imports and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "sns.set_context('notebook') \n",
    "sns.set_style('ticks') \n",
    "colours = ['#1F77B4', '#FF7F0E', '#2CA02C', '#DB2728', '#9467BD', '#8C564B', '#E377C2','#7F7F7F', '#BCBD22', '#17BECF']\n",
    "crayon = ['#4E79A7','#F28E2C','#E15759','#76B7B2','#59A14F', '#EDC949','#AF7AA1','#FF9DA7','#9C755F','#BAB0AB']\n",
    "sns.set_palette(colours)\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, confusion_matrix, log_loss\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Twitter Airline Sentiment Data\n",
    "\n",
    "In this lesson we revisit the Twitter airline sentiment dataset. To save time, we directly load the processed dataset that we constructed in the earlier lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>tokens</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[@virginamerica, it', realli, aggress, blast, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[@virginamerica, it', realli, big, bad, thing]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[@virginamerica, serious, would, pay, 30, flig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YupitsTate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:53:27 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>[@virginamerica, amaz, arriv, hour, earli, you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>570289724453216256</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HyperCamiLax</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:30:40 -0800</td>\n",
       "      <td>NYC</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>[@virginamerica, &lt;3, pretti, graphic, much, be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "3   570301031407624196          negative                           1.0   \n",
       "4   570300817074462722          negative                           1.0   \n",
       "5   570300767074181121          negative                           1.0   \n",
       "9   570295459631263746          positive                           1.0   \n",
       "11  570289724453216256          positive                           1.0   \n",
       "\n",
       "   negativereason  negativereason_confidence         airline  \\\n",
       "3      Bad Flight                     0.7033  Virgin America   \n",
       "4      Can't Tell                     1.0000  Virgin America   \n",
       "5      Can't Tell                     0.6842  Virgin America   \n",
       "9             NaN                        NaN  Virgin America   \n",
       "11            NaN                        NaN  Virgin America   \n",
       "\n",
       "   airline_sentiment_gold          name negativereason_gold  retweet_count  \\\n",
       "3                     NaN      jnardino                 NaN              0   \n",
       "4                     NaN      jnardino                 NaN              0   \n",
       "5                     NaN      jnardino                 NaN              0   \n",
       "9                     NaN    YupitsTate                 NaN              0   \n",
       "11                    NaN  HyperCamiLax                 NaN              0   \n",
       "\n",
       "                                                 text tweet_coord  \\\n",
       "3   @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4   @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "9   @VirginAmerica it was amazing, and arrived an ...         NaN   \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...         NaN   \n",
       "\n",
       "                tweet_created tweet_location               user_timezone  \\\n",
       "3   2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)   \n",
       "4   2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)   \n",
       "5   2015-02-24 11:14:33 -0800            NaN  Pacific Time (US & Canada)   \n",
       "9   2015-02-24 10:53:27 -0800    Los Angeles  Eastern Time (US & Canada)   \n",
       "11  2015-02-24 10:30:40 -0800            NYC            America/New_York   \n",
       "\n",
       "                                               tokens  positive  \n",
       "3   [@virginamerica, it', realli, aggress, blast, ...         0  \n",
       "4      [@virginamerica, it', realli, big, bad, thing]         0  \n",
       "5   [@virginamerica, serious, would, pay, 30, flig...         0  \n",
       "9   [@virginamerica, amaz, arriv, hour, earli, you...         1  \n",
       "11  [@virginamerica, <3, pretti, graphic, much, be...         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Datasets/processed_tweets.pickle')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14625</th>\n",
       "      <td>@AmericanAir Flight 236 was great. Fantastic c...</td>\n",
       "      <td>[@americanair, flight, 236, great, fantast, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14626</th>\n",
       "      <td>@AmericanAir Flight 953 NYC-Buenos Aires has b...</td>\n",
       "      <td>[@americanair, flight, 953, nyc-bueno, air, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14627</th>\n",
       "      <td>@AmericanAir Flight Cancelled Flightled, can't...</td>\n",
       "      <td>[@americanair, flight, cancel, flightl, can't,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>Thank you. “@AmericanAir: @jlhalldc Customer R...</td>\n",
       "      <td>[thank, “, @americanair, @jlhalldc, custom, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14629</th>\n",
       "      <td>@AmericanAir How do I change my flight if the ...</td>\n",
       "      <td>[@americanair, chang, flight, phone, system, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>@AmericanAir Thanks! He is.</td>\n",
       "      <td>[@americanair, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>@AmericanAir thx for nothing on getting us out...</td>\n",
       "      <td>[@americanair, thx, noth, get, us, countri, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "      <td>[@americanair, flight, cancel, flightl, leav, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>[@americanair, leav, 20, minut, late, flight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>[@americanair, money, chang, flight, don't, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "14625  @AmericanAir Flight 236 was great. Fantastic c...   \n",
       "14626  @AmericanAir Flight 953 NYC-Buenos Aires has b...   \n",
       "14627  @AmericanAir Flight Cancelled Flightled, can't...   \n",
       "14628  Thank you. “@AmericanAir: @jlhalldc Customer R...   \n",
       "14629  @AmericanAir How do I change my flight if the ...   \n",
       "14630                        @AmericanAir Thanks! He is.   \n",
       "14631  @AmericanAir thx for nothing on getting us out...   \n",
       "14633  @AmericanAir my flight was Cancelled Flightled...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "\n",
       "                                                  tokens  \n",
       "14625  [@americanair, flight, 236, great, fantast, ca...  \n",
       "14626  [@americanair, flight, 953, nyc-bueno, air, de...  \n",
       "14627  [@americanair, flight, cancel, flightl, can't,...  \n",
       "14628  [thank, “, @americanair, @jlhalldc, custom, re...  \n",
       "14629  [@americanair, chang, flight, phone, system, k...  \n",
       "14630                              [@americanair, thank]  \n",
       "14631  [@americanair, thx, noth, get, us, countri, ba...  \n",
       "14633  [@americanair, flight, cancel, flightl, leav, ...  \n",
       "14636  [@americanair, leav, 20, minut, late, flight, ...  \n",
       "14638  [@americanair, money, chang, flight, don't, an...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['text','tokens']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split indexes\n",
    "index_train, index_test  = train_test_split(np.array(data.index), train_size=0.7, random_state=1)\n",
    "\n",
    "# Write training and test sets \n",
    "train = data.loc[index_train,:].copy()\n",
    "test =  data.loc[index_test,:].copy()\n",
    "\n",
    "y_train = train['positive'].values\n",
    "y_test = test['positive'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data preparation\n",
    "\n",
    "Compute frequency distribution of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist()\n",
    "for words in train['tokens']:\n",
    "    for word in words:\n",
    "            fdist[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard features with too few appearances, retrieve list of remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.Series(dict(fdist))\n",
    "features = features.sort_values(ascending=False)\n",
    "features = features[features>=5]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank features based on univariate performance, if we want to include screening.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def univariate_design_matrix(feature, series):\n",
    "    X=series.apply(lambda tokens: (feature in tokens))\n",
    "    X= X.astype(int) \n",
    "    return X.values.reshape((-1,1)) # converting to a NumPy matrix, as requiresd\n",
    "\n",
    "def training_error(feature):\n",
    "    X_train = univariate_design_matrix(feature, train['tokens'])\n",
    "    nbc= BernoulliNB().fit(X_train, np.ravel(y_train))\n",
    "    prob = nbc.predict_proba(X_train)\n",
    "    return log_loss(y_train, prob)\n",
    "\n",
    "losses=[]\n",
    "for feature in features.index:\n",
    "    losses.append(training_error(feature))\n",
    "\n",
    "ranked = pd.Series(losses, index=features.index)\n",
    "ranked = ranked.sort_values()\n",
    "ranked_features = list(ranked.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build design matrix (slow to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def design_matrix(features, series):\n",
    "    X = lil_matrix((len(series),len(features))) # initialise \n",
    "    for i in range(len(series)): \n",
    "        tokens = series.iloc[i]\n",
    "        for j, feature in enumerate(features): # scan the list of features\n",
    "            if feature in tokens: # if the feature is among the tokens, \n",
    "                X[i, j]= 1.0\n",
    "    return X\n",
    "\n",
    "X_train = design_matrix(ranked_features, train['tokens'])\n",
    "X_test = design_matrix(ranked_features, test['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Models\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc= BernoulliNB()\n",
    "nbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Regularised Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=50, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "           refit=True, scoring='neg_log_loss', solver='liblinear',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_l1= LogisticRegressionCV(Cs = 50, penalty='l1', solver='liblinear', scoring='neg_log_loss')\n",
    "logit_l1.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(logit_l1.coef_) == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=50, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring='neg_log_loss', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_l2= LogisticRegressionCV(Cs = 50, penalty='l2', scoring='neg_log_loss')\n",
    "logit_l2.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by randomised search: {'min_samples_leaf': 5, 'max_features': 250} \n",
      "\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(criterion = 'entropy',  n_estimators=100)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'min_samples_leaf': [5, 10, 20, 50],\n",
    "    'max_features': np.arange(50, X_train.shape[1], 50),\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(model, tuning_parameters, cv = 5, n_iter= 16, scoring='neg_log_loss',\n",
    "                               return_train_score=False, n_jobs=4)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "rf = rf_search.best_estimator_\n",
    "\n",
    "print('Best parameters found by randomised search:', rf_search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by randomised search: {'reg_alpha': 0.0011613350732448448, 'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1} \n",
      "\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "alphas = [0] + list(np.logspace(-10, 10, 81, base=2))\n",
    "\n",
    "tuning_parameters = {\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'n_estimators' : [250, 500, 750, 1000, 1500, 2000, 2500, 3000, 5000],\n",
    "    'max_depth' : [1, 2, 3, 4],\n",
    "    'reg_alpha': alphas,\n",
    "}\n",
    "\n",
    "\n",
    "gb_search = RandomizedSearchCV(model, tuning_parameters, n_iter = 32, cv = 5,  scoring='neg_log_loss',\n",
    "                               return_train_score=False, n_jobs=4, random_state = 10)\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "gb = gb_search.best_estimator_\n",
    "\n",
    "print('Best parameters found by randomised search:', gb_search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAF5CAYAAABZQrRcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVBJkiQ1yIBKkiSpQQZUkiRJDfr/GrV0MrMuam8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x180226ed6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statlearning import plot_feature_importance\n",
    "plot_feature_importance(gb, ranked_features, max_features=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search: {'C': 0.25} \n",
      "\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Cs = np.logspace(-10, 10, 81, base=2)\n",
    "\n",
    "model = LinearSVC(loss='hinge')\n",
    "\n",
    "tuning_parameters ={\n",
    "    'C': Cs,\n",
    "}\n",
    "\n",
    "svm_search = GridSearchCV(model, tuning_parameters, cv=5, return_train_score=False, n_jobs=4)\n",
    "svm_search.fit(X_train, y_train)\n",
    "\n",
    "svm = svm_search.best_estimator_\n",
    "\n",
    "print('Best parameters found by grid search:', svm_search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clfs = [('clf1', nbc), ('clf2',  logit_l1), ('clf3',  logit_l2),  ('clf4',  gb), ('clf5',  svm) ]\n",
    "\n",
    "vhard = VotingClassifier(clfs)\n",
    "vhard.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfs = [('clf1', nbc), ('clf2', logit_l1), ('clf3',  logit_l2), ('clf4',  gb)]\n",
    "# We exclude SVM since it does not esimate probabilities\n",
    "\n",
    "vsoft = VotingClassifier(clfs, voting='soft')\n",
    "vsoft.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking\n",
    "\n",
    "The stacking classifier from mlxtend is not compatible with XGBoost in our setting, so that we unfortunately have to exclude boosting from the stacking ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "stack = StackingCVClassifier([nbc, logit_l1, logit_l2], use_probas=True, meta_classifier = LogisticRegression(C=1e4),\n",
    "                             store_train_meta_features=True)\n",
    "stack.fit(X_train.todense(), y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic L1</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic L2</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.082</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosting</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard Voting</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stack</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Error rate  Sensitivity  Specificity    AUC  Precision\n",
       "Naive Bayes         0.055        0.851        0.965  0.979      0.837\n",
       "Logistic L1         0.054        0.808        0.975  0.978      0.872\n",
       "Logistic L2         0.052        0.793        0.980  0.981      0.893\n",
       "Random Forest       0.082        0.694        0.966  0.939      0.809\n",
       "Boosting            0.050        0.802        0.981  0.978      0.899\n",
       "Linear SVM          0.051        0.804        0.980  0.000      0.894\n",
       "Hard Voting         0.048        0.817        0.980  0.000      0.896\n",
       "Soft Voting         0.046        0.830        0.981  0.983      0.900\n",
       "Stack               0.046        0.834        0.979  0.983      0.894"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['Error rate', 'Sensitivity', 'Specificity', 'AUC', 'Precision']\n",
    "rows=['Naive Bayes', 'Logistic L1', 'Logistic L2', 'Random Forest', \n",
    "      'Boosting', 'Linear SVM', 'Hard Voting', 'Soft Voting', 'Stack']\n",
    "\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[nbc, logit_l1, logit_l2, rf, gb, svm, vhard, vsoft, stack]\n",
    "\n",
    "y_prob = np.zeros((len(test), len(rows)))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i < 8:\n",
    "        y_pred = method.predict(X_test)\n",
    "    else:\n",
    "        y_pred = method.predict(X_test.todense())\n",
    "    \n",
    "   \n",
    "    try:  # this try block is necessary because hard voting and SVM are not compatible with probability predictions\n",
    "        if i < 8:\n",
    "            y_prob[:, i] = method.predict_proba(X_test)[:,1]\n",
    "            results.iloc[i,3]=  roc_auc_score(y_test, y_prob[:,i])\n",
    "        else: \n",
    "            y_prob[:, i] = method.predict_proba(X_test.todense())[:,1]\n",
    "            results.iloc[i,3]=  roc_auc_score(y_test, y_prob[:,i])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    confusion  = confusion_matrix(y_test, y_pred) \n",
    "    results.iloc[i,0]=  1 - accuracy_score(y_test, y_pred)\n",
    "    results.iloc[i,1]=  confusion[1,1]/np.sum(confusion[1,:])\n",
    "    results.iloc[i,2]=  confusion[0,0]/np.sum(confusion[0,:])\n",
    "    \n",
    "    results.iloc[i,4]=  precision_score(y_test, y_pred)\n",
    "\n",
    "results.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
